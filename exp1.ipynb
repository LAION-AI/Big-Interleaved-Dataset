{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('~/data/bild/00000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle')\n",
    "ngram_range = (3, 20)\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_ngrams(before_text, after_text, sent_tokenizer, ngram_range, word_tokenizer):\n",
    "    candidates = sent_tokenizer.tokenize(before_text) + sent_tokenizer.tokenize(after_text)\n",
    "\n",
    "    filtered_candidates = []\n",
    "    for i in range(len(candidates)):\n",
    "        for n in range(*ngram_range):\n",
    "            for item in ngrams(candidates[i].split(), n):\n",
    "                item = \" \".join(item)\n",
    "                word_tokens = word_tokenizer(item)\t\n",
    "                adj_present = False\n",
    "                verb_or_noun_present = False\n",
    "\n",
    "                for word in word_tokens:\n",
    "                    wordtype = set()\n",
    "                    for tmp in wn.synsets(word):\n",
    "                        if tmp.name().split('.')[0] == word:\n",
    "                            wordtype.add(tmp.pos())\n",
    "\n",
    "                    if ('a' in wordtype or 's' in wordtype):\n",
    "                        adj_present = True\n",
    "\n",
    "                    if ('n' in wordtype or 'v' in wordtype):\n",
    "                        verb_or_noun_present = True\n",
    "\n",
    "                    if adj_present and verb_or_noun_present:\n",
    "                        filtered_candidates.append(item)\n",
    "                        break\n",
    "\n",
    "    return filtered_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32-quickgelu', pretrained='laion400m_e32')\n",
    "model = model.to('cuda')\n",
    "clip_tokenizer = open_clip.get_tokenizer('ViT-B-32-quickgelu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06b471ac1a84677b413deec77906e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "tc = nltk.classify.textcat.TextCat() \n",
    "\n",
    "idxs = []\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "\tif (tc.guess_language(df.iloc[i]['Text']) == 'eng') and (df.iloc[i]['Page_config']['img_count'] > 0):\n",
    "\t\tidxs.append(i)\n",
    "\n",
    "df_subset = df.iloc[idxs]\n",
    "df_subset.to_parquet('00000_subset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = [23]\n",
    "\n",
    "# Loop through all html\n",
    "for idx in tqdm(idxs[10:]):\n",
    "    print (idx)\n",
    "    row = df.iloc[idx]\n",
    "\n",
    "    # Ignore if # of images is 0\n",
    "    #if row['Page_config']['img_count'] == 0: \n",
    "    #    continue\n",
    "\n",
    "    text = row['Text']\n",
    "    \n",
    "    img_to_url = json.loads(row['Imgs'])\n",
    "\n",
    "    # Get start and end indices of every image tag in text\n",
    "    # Hack think more about this\n",
    "    img_to_idxs = [re.search(img_name, text).span() for img_name in img_to_url.keys() if img_name in text]\n",
    "    \n",
    "    last_end = 0\n",
    "    # For every image \n",
    "    for idx, (img_name, img_url) in enumerate(img_to_url.items()):\n",
    "        # Check if image is jpeg, png\n",
    "        if (\"jpeg\" not in img_url) and (\"png\" not in img_url):\n",
    "            continue\n",
    "        \n",
    "        # Download image and ignore if size is <5KB\n",
    "        try:\n",
    "            img_data = requests.get(img_url).content\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        if sys.getsizeof(img_data) * 1e-3 < 5:\n",
    "            continue\n",
    "\n",
    "        # get text before and text after image\n",
    "        start, end = img_to_idxs[idx]\n",
    "        before_text = text[last_end:start]\n",
    "        last_end = end\n",
    "\n",
    "        if idx == (len(img_to_idxs) - 1):\n",
    "            after_text = text[end:]\n",
    "        else:\n",
    "            after_text = text[end:img_to_idxs[idx + 1][0]]\n",
    "\n",
    "        # Get filtered ngrams for image before and after \n",
    "        candidates = get_filtered_ngrams(before_text, after_text, sent_tokenizer, ngram_range, word_tokenize)\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "\n",
    "        image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # Read in image\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            inp_image = preprocess(image).unsqueeze(0).to('cuda')\n",
    "            tokenized_text = clip_tokenizer(candidates).to('cuda')\n",
    "\n",
    "            image_features = model.encode_image(inp_image)\n",
    "            text_features = model.encode_text(tokenized_text)\n",
    "\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            dot_prod = image_features @ text_features.T\n",
    "        \n",
    "            maximum, argmax = dot_prod.max(dim=-1)\n",
    "\n",
    "            if maximum > 0.0:\n",
    "                print (candidates[argmax.cpu.item()], maximum)\n",
    "                display(image)\n",
    "                time.sleep(15)\n",
    "#                 import pdb; pdb.set_trace()\n",
    "#                 print ('hello')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e865693b12835051dd37bca9be28a1ef26ef0a2eac93943edd995bac4abb6ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
